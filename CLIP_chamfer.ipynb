{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5eb0eb-f374-45e8-9cc6-314363c5170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "import sys\n",
    "sys.path.append(\"/home/beast/Desktop/vlassis/retrieval2/experiments\")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "from scripts.dataset import Items3Dataset, Warehouse4Dataset, warehouse4_collate_fn \n",
    "from scripts.visualization import quick_vis, quick_vis_with_parts, quick_vis_many\n",
    "from scripts.visualization import quick_vis_with_arrows, rotation_matrix_from_vectors_batch\n",
    "from scripts.visualization import create_arrow, create_arrows\n",
    "from scripts.model import *\n",
    "from scripts.logger import LivePlot\n",
    "from scripts.metrics import AccuracyMultiClass\n",
    "from scripts.utils import map_labels, generate_label_map, normalize_parts, normalize_parts_1\n",
    "from scripts.utils import normalize_and_split, subsample_parts, split_into_parts_without_padding\n",
    "from scripts.extensions import chamfer_dist\n",
    "import math\n",
    "import time\n",
    "\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e51c2-aaad-4769-a2d0-3d3779a443e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chamfer Hinge Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c87ab1-de23-4869-b3ca-4b5aaaaab416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChamferDistHingeLoss():\n",
    "    \n",
    "    def __init__(self, dmin, dmax, Tmax, num_steps):\n",
    "        self.dmin = dmin\n",
    "        self.dmax = dmax\n",
    "        self.num_steps = num_steps\n",
    "        self.Tmax = Tmax\n",
    "        \n",
    "        self.T = 0.01\n",
    "        self.counter = 0.0\n",
    "        self.step_val = Tmax / num_steps\n",
    "        self.criterion = chamfer_dist.ChamferDistanceL2_nomean()\n",
    "        \n",
    "        self.plot()\n",
    "    \n",
    "    def step(self):\n",
    "        self.counter += self.step_val\n",
    "        self.T = self.Tmax * self.counter / (self.counter + 1)\n",
    "    \n",
    "    def plot(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(10,2))\n",
    "        plt.plot([0, self.Tmax], [0, 0], color='blue', linewidth=2, label = 'Range')\n",
    "        \n",
    "        x = np.linspace(0, self.Tmax, self.num_steps)\n",
    "        T = self.Tmax * x / (x + 1)\n",
    "        \n",
    "        plt.scatter(T, np.zeros_like(T), color='red', s=10, label = 'Samples')\n",
    "        plt.title(\"Training session T samples\")\n",
    "        plt.xlabel(\"T\")\n",
    "        plt.yticks([])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, parts, pid, vectors):\n",
    "        \n",
    "\n",
    "        '''\n",
    "            parts: torch.Tensor(N x 3)\n",
    "            pid: torch.Tensor(N)\n",
    "            vectors: torch.Tensor(M x 3)\n",
    "        '''\n",
    "        \n",
    "        #CAREFUL, PADDING WITH A FAR AWAY POINT AFFECTS THE NORMALIZATION!\n",
    "        print(parts.shape, pid.shape, vectors.shape)\n",
    "        \n",
    "        #splitting into parts and padding B x N x 3 -> M x N x 3\n",
    "        pad_point = torch.Tensor([0, 0, 0]).to(parts.device)\n",
    "        parts, point_mask = split_into_parts_without_padding(parts.unsqueeze(0), pid.unsqueeze(0), pad_point)\n",
    "        M = vectors.shape[0]\n",
    "        \n",
    "        #normalizing the scale (try without scale normalization to take size into account as well)\n",
    "        max_abs = (parts * parts).sum(dim=-1).max(dim=-1).values.sqrt()\n",
    "        max_abs[max_abs == 0] = 1 #setting 0 values to 1 to avoid NaNs\n",
    "        parts /= max_abs.reshape(-1, 1, 1)\n",
    "        \n",
    "        #replacing the old pad point with a far away point\n",
    "        #only after normalization\n",
    "        idx = torch.all(parts == torch.Tensor([0,0,0]).to(parts.device))\n",
    "        parts[idx] = torch.Tensor([100,100,100]).to(parts.device)\n",
    "    \n",
    "        #repeating for all-to-all calculation\n",
    "        parts1 = parts.repeat(M, 1, 1)\n",
    "        parts2 = parts.repeat_interleave(M, dim=0)\n",
    "        \n",
    "        #repeating vectors to match the shapes (can delete later to save memory)\n",
    "        v1 = vectors.repeat(M, 1)\n",
    "        v2 = vectors.repeat_interleave(M, dim=0)\n",
    "        \n",
    "        #calculating relative rotations\n",
    "        R = rotation_matrix_from_vectors_batch(v1, v2)\n",
    "        \n",
    "        #multiplying the parts by the rotation matrices\n",
    "        with torch.no_grad():\n",
    "            parts1 = (R.unsqueeze(1) @ parts1.unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        #distance calculation\n",
    "        d1, d2 = self.criterion(parts1, parts2)\n",
    "        m1, m2 = point_mask.repeat(M, 1), point_mask.repeat_interleave(M, dim=0)\n",
    "    \n",
    "        #mean calculation that ignores padded elements\n",
    "        d1 = (d1 * m1).sum(dim=-1) / m1.sum(dim=-1)\n",
    "        d2 = (d2 * m2).sum(dim=-1) / m2.sum(dim=-1)\n",
    "    \n",
    "        #reshaping into square matrix\n",
    "        d1 = d1.reshape(M, M)\n",
    "        d2 = d2.reshape(M, M)\n",
    "        \n",
    "        #mean between distances from both directions\n",
    "        d = (d1 + d2) / 2\n",
    "        \n",
    "        #hinge loss calculation\n",
    "        hinge = 1 - (torch.exp(self.T*d) - math.exp(self.dmin*self.T)) / (math.exp(self.T*self.dmax) - math.exp(self.dmin*self.T))\n",
    "        \n",
    "        return hinge #, parts1, parts2, v1, v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7803b8-ee87-4757-a7fa-748599ebb615",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data & Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538c6bfb-ee86-4dd0-a2ef-d0dcbe9eff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10406,)\n",
      "Items2 dataset initialization complete (t = 3.197326898574829)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x71fd7ff8de50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "data_path = \"/home/beast/Desktop/vlassis/retrieval2/experiments/data/vectors2_items2_partnet.h5\"\n",
    "\n",
    "#data\n",
    "batch_size = 48\n",
    "categories = [0, 1, 3]\n",
    "dataset = Items3Dataset(cat=categories, path = data_path)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#model\n",
    "model = PartFinderPipeline2(in_channels = 3, out_channels = 384,\n",
    "                            num_classes = len(categories),\n",
    "                            num_attention_blocks = 3,\n",
    "                            pos_emb_dim = 3,\n",
    "                            pool_method = \"cls_token_pool\"\n",
    "                           ).cuda()\n",
    "\n",
    "\n",
    "#training params\n",
    "num_epochs = 50\n",
    "lr, warmup_steps = 1e-3, 100\n",
    "current_epoch = 0\n",
    "num_parts_keep = 64\n",
    "\n",
    "#initialize optimizer\n",
    "opt = torch.optim.Adam(model.encoder.parameters(), lr=lr, weight_decay=1e-5)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer = opt,\n",
    "    num_warmup_steps = warmup_steps,\n",
    "    num_training_steps = len(dataloader) * num_epochs\n",
    ")\n",
    "\n",
    "#logger\n",
    "logger = LivePlot()\n",
    "\n",
    "#loss function\n",
    "criterion = ChamferDistHingeLoss(0, 0.6, 15, len(dataloader) * num_epochs)\n",
    "\n",
    "#metrics\n",
    "m1 = AccuracyMultiClass()\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056aace0-51d8-49ee-a5d3-282dfa64f3c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd525e2a-7398-438a-af26-3a25d831e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, opt, lr_scheduler, criterion, logger):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    steps = 0\n",
    "    global num_parts_keep\n",
    "         \n",
    "    for shape, _, part_label, pid, vectors in dataloader:\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        #passing data to gpu\n",
    "        shape, part_label, pid, vectors = shape.cuda(), part_label.cuda(), pid.cuda(), vectors.cuda()\n",
    "\n",
    "        #normalizing the parts - N x 3, N, M, M x 3\n",
    "        parts, pid, part_label, vectors = normalize_and_split(shape, pid, part_label, vectors)\n",
    "\n",
    "        #shuffling and grabbing a random subset N' x 3, N', M', M' x 3\n",
    "        parts, pid, part_label, vectors = subsample_parts(parts, pid, part_label, vectors, num_parts_keep)\n",
    "\n",
    "        #running the model - M' x F\n",
    "        part_feats = model.forward_encoder(parts, pid, num_parts_keep)\n",
    "        \n",
    "        #normalizing the feature vectors M' x F\n",
    "        part_feats = torch.nn.functional.normalize(part_feats, p=2, dim=-1)\n",
    "\n",
    "        #forming similarity matrix M' x M'\n",
    "        similarity_matrix = part_feats @ part_feats.T\n",
    "        \n",
    "        print(parts.shape, pid.shape, vectors.shape)\n",
    "\n",
    "        #chamfer hinge criterion\n",
    "        ch_dist = criterion(parts, pid, vectors)\n",
    "\n",
    "        #forming the ground truth similarity matrix\n",
    "        part_lbs_expanded = part_label.unsqueeze(0).repeat(part_label.shape[0],1)\n",
    "        gt_similarity = part_lbs_expanded == part_lbs_expanded.T\n",
    "        gt_similarity = (gt_similarity.float() + ch_dist * (~gt_similarity).float())\n",
    "\n",
    "        #loss calculation \n",
    "        loss = ((gt_similarity - similarity_matrix)**2).mean()\n",
    "\n",
    "        #back propagation\n",
    "        loss.backward()\n",
    "\n",
    "        #gradient clipping\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "\n",
    "        #logger updates\n",
    "        logger.on_step(loss.item())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        steps +=1\n",
    "\n",
    "        #optimizer\n",
    "        opt.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        criterion.step()      \n",
    "    \n",
    "    return epoch_loss / steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba01f213-a9b7-4128-99d9-314c09ec896c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 4\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# acc = eval_epoch(model, test_dataloader, m1)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, opt, lr_scheduler, criterion, logger)\u001b[0m\n\u001b[1;32m     45\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#gradient clipping\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#logger updates\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     54\u001b[0m steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/vlassis/retrieval2/experiments/scripts/logger.py:52\u001b[0m, in \u001b[0;36mLivePlot.on_step\u001b[0;34m(self, sample)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, sample):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_losses\u001b[38;5;241m.\u001b[39mappend(sample)\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/vlassis/retrieval2/experiments/scripts/logger.py:41\u001b[0m, in \u001b[0;36mLivePlot.update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m     40\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/matplotlib/pyplot.py:389\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    388\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/matplotlib_inline/backend_inline.py:41\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 41\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/IPython/core/formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    176\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/IPython/core/formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/IPython/core/formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    341\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/IPython/core/pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 151\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/matplotlib/backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2317\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2318\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2319\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2322\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2323\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2324\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/matplotlib/backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     _api\u001b[38;5;241m.\u001b[39mwarn_deprecated(\n\u001b[1;32m   1641\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.3\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39mname, removal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1642\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m() got unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1643\u001b[0m                 \u001b[38;5;241m+\u001b[39m arg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m which is no longer supported as of \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1644\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m and will become an error \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1645\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1646\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(arg)\n\u001b[0;32m-> 1648\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/matplotlib/_api/deprecation.py:415\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     deprecation_addendum \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf any parameter follows \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m, they should be passed as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeyword, not positionally.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m     warn_deprecated(\n\u001b[1;32m    409\u001b[0m         since,\n\u001b[1;32m    410\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrepr\u001b[39m(name),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m                  \u001b[38;5;28;01melse\u001b[39;00m deprecation_addendum,\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 415\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:541\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03mWrite the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    540\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 541\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/matplotlib/image.py:1675\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1673\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1674\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1675\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/PIL/Image.py:2320\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2317\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2320\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/PIL/PngImagePlugin.py:1374\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     _write_multiple_frames(im, fp, chunk, rawmode)\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1377\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/anaconda3/envs/votenet/lib/python3.9/site-packages/PIL/ImageFile.py:518\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m         l, s, d \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(d)\n\u001b[1;32m    520\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "for i in range(num_epochs):\n",
    "        \n",
    "    epoch_loss = train_epoch(model, dataloader, opt, lr_scheduler, criterion, logger)\n",
    "    # acc = eval_epoch(model, test_dataloader, m1)\n",
    "    acc = 0\n",
    "    logger.on_epoch(i, epoch_loss, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab3d2c-75ef-4e7f-a95d-b32e80261e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/beast/Desktop/vlassis/retrieval2/checkpoints/partnet_pointnetnew_batchless.pt\"\n",
    "torch.save(model.encoder.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a262907-cd37-4784-9240-5b755868b1e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CHAMFER LOSS MATRIX VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c39b16-62d3-433e-9092-a010716f4cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChamferDistHingeLoss():\n",
    "    \n",
    "    def __init__(self, dmin, dmax, Tmax, num_steps):\n",
    "        self.dmin = dmin\n",
    "        self.dmax = dmax\n",
    "        self.num_steps = num_steps\n",
    "        self.Tmax = Tmax\n",
    "        \n",
    "        self.T = 0.01\n",
    "        self.counter = 0.0\n",
    "        self.step_val = Tmax / num_steps\n",
    "        self.criterion = chamfer_dist.ChamferDistanceL2_nomean()\n",
    "        \n",
    "        self.plot()\n",
    "    \n",
    "    def step(self):\n",
    "        self.counter += self.step_val\n",
    "        self.T = self.Tmax * self.counter / (self.counter + 1)\n",
    "    \n",
    "    def plot(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(10,2))\n",
    "        plt.plot([0, self.Tmax], [0, 0], color='blue', linewidth=2, label = 'Range')\n",
    "        \n",
    "        x = np.linspace(0, self.Tmax, self.num_steps)\n",
    "        T = self.Tmax * x / (x + 1)\n",
    "        \n",
    "        plt.scatter(T, np.zeros_like(T), color='red', s=10, label = 'Samples')\n",
    "        plt.title(\"Training session T samples\")\n",
    "        plt.xlabel(\"T\")\n",
    "        plt.yticks([])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, parts, pid, vectors):\n",
    "        \n",
    "\n",
    "        '''\n",
    "            parts: torch.Tensor(N x 3)\n",
    "            pid: torch.Tensor(N)\n",
    "            vectors: torch.Tensor(M x 3)\n",
    "        '''\n",
    "        \n",
    "        #CAREFUL, PADDING WITH A FAR AWAY POINT AFFECTS THE NORMALIZATION!\n",
    "        print(parts.shape, pid.shape, vectors.shape)\n",
    "        \n",
    "        #splitting into parts and padding B x N x 3 -> M x N x 3\n",
    "        pad_point = torch.Tensor([0, 0, 0]).to(parts.device)\n",
    "        parts, point_mask = split_into_parts_without_padding(parts.unsqueeze(0), pid.unsqueeze(0), pad_point)\n",
    "        M = vectors.shape[0]\n",
    "        \n",
    "        #normalizing the scale (try without scale normalization to take size into account as well)\n",
    "        max_abs = (parts * parts).sum(dim=-1).max(dim=-1).values.sqrt()\n",
    "        max_abs[max_abs == 0] = 1 #setting 0 values to 1 to avoid NaNs\n",
    "        parts /= max_abs.reshape(-1, 1, 1)\n",
    "        \n",
    "        #replacing the old pad point with a far away point\n",
    "        #only after normalization\n",
    "        idx = torch.all(parts == torch.Tensor([0,0,0]).to(parts.device))\n",
    "        parts[idx] = torch.Tensor([100,100,100]).to(parts.device)\n",
    "    \n",
    "        #repeating for all-to-all calculation\n",
    "        parts1 = parts.repeat(M, 1, 1)\n",
    "        parts2 = parts.repeat_interleave(M, dim=0)\n",
    "        \n",
    "        #repeating vectors to match the shapes (can delete later to save memory)\n",
    "        v1 = vectors.repeat(M, 1)\n",
    "        v2 = vectors.repeat_interleave(M, dim=0)\n",
    "        \n",
    "        #calculating relative rotations\n",
    "        R = rotation_matrix_from_vectors_batch(v1, v2)\n",
    "        \n",
    "        #multiplying the parts by the rotation matrices\n",
    "        with torch.no_grad():\n",
    "            parts1 = (R.unsqueeze(1) @ parts1.unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        #distance calculation\n",
    "        d1, d2 = self.criterion(parts1, parts2)\n",
    "        m1, m2 = point_mask.repeat(M, 1), point_mask.repeat_interleave(M, dim=0)\n",
    "    \n",
    "        #mean calculation that ignores padded elements\n",
    "        d1 = (d1 * m1).sum(dim=-1) / m1.sum(dim=-1)\n",
    "        d2 = (d2 * m2).sum(dim=-1) / m2.sum(dim=-1)\n",
    "    \n",
    "        #reshaping into square matrix\n",
    "        d1 = d1.reshape(M, M)\n",
    "        d2 = d2.reshape(M, M)\n",
    "        \n",
    "        #mean between distances from both directions\n",
    "        d = (d1 + d2) / 2\n",
    "        \n",
    "        #hinge loss calculation\n",
    "        hinge = 1 - (torch.exp(self.T*d) - math.exp(self.dmin*self.T)) / (math.exp(self.T*self.dmax) - math.exp(self.dmin*self.T))\n",
    "        \n",
    "        v1 = (R.double() @ v1.unsqueeze(-1)).squeeze()\n",
    "        \n",
    "        \n",
    "        return hinge, parts1, parts2, v1, v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be88180-8ec5-4b08-8590-20fd9335bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "data_path = \"/home/beast/Desktop/vlassis/retrieval2/experiments/data/vectors2_items2_partnet.h5\"\n",
    "\n",
    "#data\n",
    "batch_size = 48\n",
    "categories = [0, 1, 3]\n",
    "dataset = Items3Dataset(cat=categories, path = data_path)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#\n",
    "num_epochs = 50\n",
    "num_parts_keep = 32\n",
    "\n",
    "#loss function\n",
    "criterion = ChamferDistHingeLoss(0, 0.6, 15, len(dataloader) * num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cd0d3-13fe-402c-bef3-3c88d7992dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "#grabbing a sample from the dataloader\n",
    "shape, _, part_label, pid, vectors = next(iter(dataloader))\n",
    "\n",
    "#passing data to gpu\n",
    "shape, part_label, pid, vectors = shape.cuda(), part_label.cuda(), pid.cuda(), vectors.cuda()\n",
    "\n",
    "#normalizing the parts - N x 3, N, M, M x 3\n",
    "parts, pid, part_label, vectors = normalize_and_split(shape, pid, part_label, vectors)\n",
    "\n",
    "#shuffling and grabbing a random subset N' x 3, N', M', M' x 3\n",
    "parts, pid, part_label, vectors = subsample_parts(parts, pid, part_label, vectors, num_parts_keep)\n",
    "\n",
    "#chamfer hinge criterion\n",
    "ch_dist, parts1, parts2, vecs1, vecs2 = criterion(parts, pid, vectors)\n",
    "ch_dist = ch_dist.cpu().detach().numpy()\n",
    "\n",
    "fig = go.FigureWidget([\n",
    "    go.Heatmap(\n",
    "        z=ch_dist,\n",
    "        colorscale='Viridis'\n",
    "    )\n",
    "])\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,  # Adjust the width as necessary\n",
    "    height=800,  # Adjust the height as necessary\n",
    "    margin=dict(l=80, r=80, b=80, t=80),\n",
    "    xaxis=dict(scaleanchor=\"y\", scaleratio=1)\n",
    ")\n",
    "\n",
    "def show_point_clouds(trace, points, selector):\n",
    "    i, j = points.point_inds[0]\n",
    "    print(f\"Selected cell: ({i}, {j})\")\n",
    "    # Add your code to visualize the aligned point clouds i and j\n",
    "    # For example, using matplotlib or plotly 3D scatter plot\n",
    "\n",
    "    M = ch_dist.shape[0]\n",
    "\n",
    "    pcs = [\n",
    "        parts1[i * M + j],\n",
    "        parts2[i * M + j]\n",
    "    ]\n",
    "\n",
    "    vecs = torch.stack((\n",
    "        vecs1[i * M + j],\n",
    "        vecs2[i * M + j]\n",
    "    ))\n",
    "\n",
    "    quick_vis_with_arrows(pcs, vecs, title= f\"distance: {ch_dist[i, j]}\")\n",
    "\n",
    "heatmap = fig.data[0]\n",
    "heatmap.on_click(show_point_clouds)\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657ba4bc-b218-42bb-9156-adccd051a2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
